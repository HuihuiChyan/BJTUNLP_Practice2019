模仿了TextCNN的架构，用长度为3,4,5的卷积核对两个文本分别进行卷积，卷积的结果平均池化之后拼接到一起，最后过一个全连接层。

效果并不好，自我反思了一下，文本匹配任务和分类、标注任务都有很大的区别，匹配任务一定要做好两段文本之间的交互。我现在是两句话单独提取特征，直到最后要分类了才拼到一起。

可以参考ESIM模型，如果中间加一层Attention应该会好很多。

参数列表如下：

| 参数名称      | 参数值  |
| ------------- | ------- |
| kernel        | [3,4,5] |
| vocab_size    | 50000   |
| learning_rate | 1e-3    |
| max_len       | 30      |
| batch_size    | 32      |
| hidden_size   | 256     |

